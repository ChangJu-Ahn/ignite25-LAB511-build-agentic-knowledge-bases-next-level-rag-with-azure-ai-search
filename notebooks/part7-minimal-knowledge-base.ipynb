{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a0a1e1d",
   "metadata": {},
   "source": [
    "# 파트 7: 최소 지식 베이스\n",
    "\n",
    "파트 1-6에서는 완전한 에이전틱 추론 기능을 가진 지식 베이스를 사용했습니다. 파트 7에서는 일부 추론 정교함을 속도와 비용의 상당한 개선과 교환하는 **최소 추론 노력** 최적화를 살펴봅니다. 이 접근 방식은 더 간단한 쿼리에 대해 빠르고 비용 효율적인 검색이 필요할 때 이상적입니다.\n",
    "\n",
    "## 단계 1: 환경 변수 로드\n",
    "\n",
    "아래 셀을 실행하여 Azure 리소스의 구성을 로드하고, 생성된 **.venv(3.11.9)** 환경을 선택하세요.\n",
    "\n",
    "이번에는 최소 추론 노력에 최적화된 지식 베이스를 생성합니다.\n",
    "\n",
    "> **⚠️ 문제 해결**\n",
    ">\n",
    "> 코드 셀이 멈추고 계속 돌아가면 노트북 상단 툴바에서 **Restart**를 선택하세요. 몇 번 시도해도 문제가 지속되면 VS Code를 완전히 닫고 다시 여세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88564a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True) # take environment variables from .env.\n",
    "\n",
    "# Azure AI Search configuration\n",
    "endpoint = os.environ[\"AZURE_SEARCH_SERVICE_ENDPOINT\"]\n",
    "credential = AzureKeyCredential(os.environ[\"AZURE_SEARCH_ADMIN_KEY\"])\n",
    "\n",
    "# Knowledge base name\n",
    "knowledge_base_name = \"minimal-knowledge-base\"\n",
    "\n",
    "# Azure OpenAI configuration\n",
    "azure_openai_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "azure_openai_key = os.environ[\"AZURE_OPENAI_KEY\"]\n",
    "azure_openai_chatgpt_deployment = os.getenv(\"AZURE_OPENAI_CHATGPT_DEPLOYMENT\", \"gpt-4.1\")\n",
    "azure_openai_chatgpt_model_name = os.getenv(\"AZURE_OPENAI_CHATGPT_MODEL_NAME\", \"gpt-4.1\")\n",
    "\n",
    "print(\"Environment variables loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b649102",
   "metadata": {},
   "source": [
    "## 단계 2: 최소 추론 지식 베이스 생성\n",
    "\n",
    "`KnowledgeRetrievalMinimalReasoningEffort`를 사용하여 속도와 비용에 최적화된 지식 베이스를 생성합니다.\n",
    "\n",
    "이전 파트와 두 가지 주요 차이점을 확인하세요:\n",
    "\n",
    "1. **Azure OpenAI 모델 구성 없음**: 지식 베이스가 LLM 기반 쿼리 계획 및 답변 합성을 건너뜁니다\n",
    "2. **`EXTRACTIVE_DATA` 출력 모드**: 합성된 답변 대신 원시 청크를 반환합니다\n",
    "\n",
    "이 구성은 정교한 추론 기능보다 속도와 비용 절감을 우선시합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5cec39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import KnowledgeBase, KnowledgeRetrievalMinimalReasoningEffort, KnowledgeRetrievalOutputMode, KnowledgeSourceReference\n",
    "\n",
    "index_client = SearchIndexClient(endpoint=endpoint, credential=credential)\n",
    "\n",
    "knowledge_base = KnowledgeBase(\n",
    "    name=knowledge_base_name,\n",
    "    knowledge_sources=[\n",
    "        KnowledgeSourceReference(name=\"healthdocs-knowledge-source\"),\n",
    "        KnowledgeSourceReference(name=\"hrdocs-knowledge-source\"),\n",
    "    ],\n",
    "    output_mode=KnowledgeRetrievalOutputMode.EXTRACTIVE_DATA,\n",
    "    retrieval_reasoning_effort=KnowledgeRetrievalMinimalReasoningEffort()\n",
    ")\n",
    "\n",
    "index_client.create_or_update_knowledge_base(knowledge_base)\n",
    "print(f\"Knowledge base '{knowledge_base_name}' created or updated successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f194ea5",
   "metadata": {},
   "source": [
    "## 단계 3: 시맨틱 인텐트로 쿼리\n",
    "\n",
    "최소 추론 지식 베이스는 대화형 메시지 대신 `KnowledgeRetrievalSemanticIntent`를 사용합니다. 각 인텐트는 지식 소스에 대한 직접 검색 쿼리로 실행됩니다.\n",
    "\n",
    "아래 코드는 두 개의 시맨틱 인텐트를 실행하고 참조와 활동 로그를 포함하지만 합성된 답변은 없는 결과를 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7becc9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.knowledgebases import KnowledgeBaseRetrievalClient\n",
    "from azure.search.documents.knowledgebases.models import KnowledgeBaseRetrievalRequest, KnowledgeRetrievalSemanticIntent, SearchIndexKnowledgeSourceParams\n",
    "\n",
    "knowledge_base_client = KnowledgeBaseRetrievalClient(endpoint=endpoint, knowledge_base_name=knowledge_base_name, credential=credential)\n",
    "healthdocs_ks_params = SearchIndexKnowledgeSourceParams(\n",
    "    knowledge_source_name=\"healthdocs-knowledge-source\",\n",
    "    include_references=True,\n",
    "    include_reference_source_data=True,\n",
    ")\n",
    "hrdocs_ks_params = SearchIndexKnowledgeSourceParams(\n",
    "    knowledge_source_name=\"hrdocs-knowledge-source\",\n",
    "    include_references=True,\n",
    "    include_reference_source_data=True,\n",
    ")\n",
    "req = KnowledgeBaseRetrievalRequest(\n",
    "    intents=[\n",
    "        KnowledgeRetrievalSemanticIntent(\n",
    "            search=\"What is the responsibility of the Zava CEO?\"\n",
    "        ),\n",
    "        KnowledgeRetrievalSemanticIntent(\n",
    "            search=\"What Zava health plan would you recommend if they wanted the best coverage for mental health services?\"\n",
    "        )\n",
    "    ],\n",
    "    knowledge_source_params=[\n",
    "        healthdocs_ks_params,\n",
    "        hrdocs_ks_params\n",
    "    ],\n",
    "    include_activity=True,\n",
    "    retrieval_reasoning_effort=KnowledgeRetrievalMinimalReasoningEffort()\n",
    ")\n",
    "result = knowledge_base_client.retrieve(retrieval_request=req)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b58cc1",
   "metadata": {},
   "source": [
    "## 단계 4: 원시 검색 데이터 검토\n",
    "\n",
    "최소 추론 지식 베이스의 결과에는 지식 소스에서 검색된 원시 데이터 청크가 포함됩니다. 최소 노력 베이스는 자체 LLM 질문-답변 로직이 있는 애플리케이션에 에이전틱 검색을 통합하거나 결과를 직접 표시할 때 유용합니다.\n",
    "\n",
    "코드를 실행하고 결과를 관찰하여 최소 추론 지식 베이스가 쿼리를 어떻게 효율적으로 처리하는지 확인하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae82fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "references = json.dumps([ref.as_dict() for ref in result.references], indent=2)\n",
    "print(references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492966b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "activity_types = [{\"type\": a.type} for a in result.activity]\n",
    "\n",
    "df = pd.DataFrame(activity_types)\n",
    "\n",
    "print(\"Activity Log Steps\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e68ac75",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_content = json.dumps([a.as_dict() for a in result.activity], indent=2)\n",
    "print(\"Activity Details\")\n",
    "print(activity_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e37ac2",
   "metadata": {},
   "source": [
    "## 단계 5: 합성된 답변 생성\n",
    "\n",
    "검색된 청크에서 합성된 답변을 원한다면 처리를 위해 LLM에 전달할 수 있습니다. 아래 코드는 추출된 데이터를 사용하여 간결한 답변을 생성하는 방법을 보여줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddb8f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "openai_client = AsyncOpenAI(\n",
    "    base_url=azure_openai_endpoint + \"openai/v1/\",\n",
    "    api_key=azure_openai_key\n",
    ")\n",
    "\n",
    "response = await openai_client.responses.create(\n",
    "    model=azure_openai_chatgpt_deployment,\n",
    "    instructions=\"You are a helpful assistant that provides concise answers based on the provided context.\",\n",
    "    input=f\"\"\"\n",
    "    Based on the following context, answer the question concisely.\\n\\nContext:\\n{result.response[0].content[0].text}\n",
    "    \\n\\nQuestion:\\nWhat is the responsibility of the Zava CEO?\n",
    "    What Zava health plan would you recommend if they wanted the best coverage for mental health services?\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "display(Markdown(response.output_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e279c41c",
   "metadata": {},
   "source": [
    "## 요약\n",
    "\n",
    "이제 정교한 추론 기능보다 속도와 비용에 최적화된 최소 추론 지식 베이스를 경험했습니다.\n",
    "\n",
    "**기억해야 할 핵심 개념:**\n",
    "- `KnowledgeRetrievalMinimalReasoningEffort`는 고급 추론보다 속도와 비용 절감을 우선시합니다\n",
    "- `EXTRACTIVE_DATA` 출력 모드는 합성된 답변 대신 원시 청크를 반환합니다\n",
    "- `KnowledgeRetrievalSemanticIntent`는 대화형 메시지 대신 집중된 검색 인텐트로 쿼리를 구조화합니다\n",
    "- 지식 베이스 구성에 Azure OpenAI 모델이 필요하지 않아 기본 비용이 줄어듭니다\n",
    "- Azure OpenAI를 사용한 선택적 후처리로 LLM 합성 사용 시기를 제어할 수 있습니다\n",
    "\n",
    "### 다음 단계\n",
    "\n",
    "➡️ [파트 8: 중간 지식 베이스](part8-medium-knowledge-base.ipynb)로 계속하여 중간 추론 노력이 정교함과 성능의 균형을 어떻게 맞추는지 배웁니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
